{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 Comparison of Classifiers\n",
    "\n",
    "## Data Description\n",
    "\n",
    "We use the **letter** dataset from Statlog. The statistics of dataset is shown in Table 1. The class number of the data is 26.\n",
    "\n",
    "| Dataset  |Size|Feature|\n",
    "|--|----|-------|\n",
    "|Train|15000|16|\n",
    "|Test|5000|16|\n",
    "\n",
    "## Comparison of Classifiers\n",
    "\n",
    "You are required to implement the following classifiers and compute the performance achieved by different classifiers.\n",
    "\n",
    "* **Decision Tree**\n",
    "  \n",
    "  You should form decision trees on dataset in terms of entropy and gini criterions. For each criterion, you should set the depth as [5,10,15,20,25] separately. You need to compare the performance (accuracy, precision, recall, f1 score and training time) and give a brief discussion.\n",
    "* **KNN, Random Forest**\n",
    "  \n",
    "  Apply three different classifiers KNN and Random Forest on the dataset. For each classifier, evaluate the performance (accuracy, precision, recall, f1 score and training time) . You are required to compare the performance of different classifiers and give a brief discussion.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def preprocess(path):\n",
    "    \"\"\"\n",
    "    Preprocess the txt file\n",
    "    \n",
    "    Input: the file path\n",
    "    Output: \n",
    "        X: a list contains all feature vectors\n",
    "        y: a list of labels\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(path) as f:\n",
    "        X, y = list(), list()\n",
    "        for line in f.readlines():\n",
    "            data = line.strip().split(\" \")\n",
    "            i = 0\n",
    "            vec = list()\n",
    "            for item in data:\n",
    "                if i == 0:\n",
    "                    y.append(item) # the first item is the label\n",
    "                else:\n",
    "                    vec.append(item.split(\":\")[1]) # traversal 16 features and form features vector\n",
    "                i += 1\n",
    "            X.append(vec)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = preprocess(\"Q1_dataset/letter_train\")\n",
    "X_test, y_test = preprocess(\"Q1_dataset/letter_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_predict, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the classifier performance by accuracy, percision, recall and f1\n",
    "    \n",
    "    Input: y_predict and the ground truth y_test\n",
    "    Output: accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "    precision = metrics.precision_score(y_test, y_predict, average=\"macro\")\n",
    "    recall = metrics.recall_score(y_test, y_predict, average=\"macro\")\n",
    "    f1 = metrics.f1_score(y_test, y_predict, average=\"macro\")\n",
    "    print(\"accuracy = \", accuracy)\n",
    "    print(\"precision = \", precision)\n",
    "    print(\"recall = \", recall)\n",
    "    print(\"f1 = \", f1)\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini, max_depth = 5\n",
      "accuracy =  0.3694\n",
      "precision =  0.3924221306348351\n",
      "recall =  0.36850352493813343\n",
      "f1 =  0.3270313126141437\n",
      "trainning time =  0.09574317932128906\n",
      "criterion = gini, max_depth = 10\n",
      "accuracy =  0.7138\n",
      "precision =  0.7636010679690324\n",
      "recall =  0.7171218331670801\n",
      "f1 =  0.7267729630119254\n",
      "trainning time =  0.10671448707580566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = gini, max_depth = 15\n",
      "accuracy =  0.8328\n",
      "precision =  0.8433642286386743\n",
      "recall =  0.8334905973140099\n",
      "f1 =  0.8359003682415955\n",
      "trainning time =  0.1266627311706543\n",
      "criterion = gini, max_depth = 20\n",
      "accuracy =  0.8648\n",
      "precision =  0.8660853178901877\n",
      "recall =  0.8651363229926136\n",
      "f1 =  0.8649724157707273\n",
      "trainning time =  0.14162158966064453\n",
      "criterion = gini, max_depth = 25\n",
      "accuracy =  0.8752\n",
      "precision =  0.8759060911437004\n",
      "recall =  0.8758210306194438\n",
      "f1 =  0.8755666418386217\n",
      "trainning time =  0.13463997840881348\n",
      "criterion = entropy, max_depth = 5\n",
      "accuracy =  0.5014\n",
      "precision =  0.5609909827716968\n",
      "recall =  0.501366857622793\n",
      "f1 =  0.49858248010632233\n",
      "trainning time =  0.0937490463256836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion = entropy, max_depth = 10\n",
      "accuracy =  0.7984\n",
      "precision =  0.8029257770797809\n",
      "recall =  0.798420071372091\n",
      "f1 =  0.7991154249568595\n",
      "trainning time =  0.11768460273742676\n",
      "criterion = entropy, max_depth = 15\n",
      "accuracy =  0.8716\n",
      "precision =  0.8721783610718289\n",
      "recall =  0.8722052134592271\n",
      "f1 =  0.871932274124534\n",
      "trainning time =  0.13065028190612793\n",
      "criterion = entropy, max_depth = 20\n",
      "accuracy =  0.8742\n",
      "precision =  0.8748118963197716\n",
      "recall =  0.8750407872449356\n",
      "f1 =  0.8746052245087904\n",
      "trainning time =  0.13065052032470703\n",
      "criterion = entropy, max_depth = 25\n",
      "accuracy =  0.8748\n",
      "precision =  0.8752430241101877\n",
      "recall =  0.8756309923714058\n",
      "f1 =  0.8751226356128214\n",
      "trainning time =  0.12768888473510742\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "criterion = [\"gini\", \"entropy\"]\n",
    "max_depth = [5, 10, 15, 20, 25]\n",
    "\n",
    "for c in criterion:\n",
    "    for m in max_depth:\n",
    "        t0 = time.time()\n",
    "        DT = DecisionTreeClassifier(criterion=c, max_depth=m)\n",
    "        DT.fit(X_train, y_train)\n",
    "        t1 = time.time()\n",
    "        y_predict = DT.predict(X_test)\n",
    "        print(\"criterion = %s, max_depth = %s\" % (c, m))\n",
    "        evaluate(y_predict, y_test)\n",
    "        print(\"trainning time = \", t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the above evaluation result, we can summarize the performance of decision tree with different parameters in this table (keep 3 significant digits)\n",
    "\n",
    "|Criterion|Max Depth|Accuracy|Precision|Recall|F1|Training Time|\n",
    "|---------|---------|---------|--------|------|--|-------------|\n",
    "|gini|5|0.369|0.392|0.368|0.327|0.0942s|\n",
    "|gini|10|0.713|0.763|0.716|0.726|0.103s|\n",
    "|gini|15|0.832|0.842|0.833|0.835|0.125s|\n",
    "|gini|20|0.867|0.869|0.867|0.867|0.126s|\n",
    "|gini|25|0.872|0.872|0.872|0.872|0.126s|\n",
    "|entropy|5|0.501|0.561|0.501|0.498|0.086s|\n",
    "|entropy|10|0.799|0.804|0.799|0.800|0.118s|\n",
    "|entropy|15|0.874|0.875|0.875|0.875|0.132s|\n",
    "|entropy|20|0.871|0.871|0.872|0.871|0.151s|\n",
    "|entropy|25|0.874|0.874|0.874|0.874|0.157s|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table, we can see that with the same parameter of max_depth, entropy always performs better than gini. It's obvious that the larger the max_depth, the better performance of the classifier with higher accuracy, precison, recall and F1 but also with longer time to train. The best accuracy that the clssifier can achieve is about 0.874."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors =  2\n",
      "accuracy =  0.9474\n",
      "precision =  0.9483786076543728\n",
      "recall =  0.9487558725937107\n",
      "f1 =  0.9475318066767836\n",
      "trainning time =  0.1904895305633545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors =  5\n",
      "accuracy =  0.9524\n",
      "precision =  0.9524332800528715\n",
      "recall =  0.9527133453583622\n",
      "f1 =  0.9523114644552255\n",
      "trainning time =  0.18749642372131348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\Users\\yelbee\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors =  8\n",
      "accuracy =  0.9482\n",
      "precision =  0.9486989364162672\n",
      "recall =  0.9484795525263109\n",
      "f1 =  0.9481845764367763\n",
      "trainning time =  0.18849420547485352\n",
      "n_estimators =  50\n",
      "accuracy =  0.9582\n",
      "precision =  0.958763912446811\n",
      "recall =  0.9584578191891976\n",
      "f1 =  0.9584704567851836\n",
      "trainning time =  0.9225304126739502\n",
      "n_estimators =  100\n",
      "accuracy =  0.961\n",
      "precision =  0.961599134728099\n",
      "recall =  0.9611258587790934\n",
      "f1 =  0.9611716900976468\n",
      "trainning time =  1.8101222515106201\n",
      "n_estimators =  150\n",
      "accuracy =  0.962\n",
      "precision =  0.9627023409630729\n",
      "recall =  0.9619864479713358\n",
      "f1 =  0.9621593877244844\n",
      "trainning time =  2.691796064376831\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_neighbors = [2, 5, 8]\n",
    "for n in n_neighbors:\n",
    "    t0 = time.time()\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n, radius=1, algorithm=\"auto\")\n",
    "    neigh.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    y_predict = neigh.predict(X_test)\n",
    "    print(\"n_neighbors = \", n)\n",
    "    evaluate(y_predict, y_test)\n",
    "    print(\"trainning time = \", t1 - t0)\n",
    "\n",
    "n_estimators = [50, 100, 150]\n",
    "for n in n_estimators:\n",
    "    t0 = time.time()\n",
    "    RF = RandomForestClassifier(n_estimators=n, criterion=\"gini\", max_depth=20)\n",
    "    RF.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    y_predict = RF.predict(X_test)\n",
    "    print(\"n_estimators = \", n)\n",
    "    evaluate(y_predict, y_test)\n",
    "    print(\"trainning time = \", t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We summarize the performance of different classifiers in the following table. Notice we tune the `n_neighbors`(number of neighbors to use for K nearest neighbors queries) in the KNN and adjust the `n_estimators`(number of trees in the forest) in RandomForest. Then we get 6 different classifiers.\n",
    "\n",
    "|Classifier|Accuracy|Precision|Recall|F1|Training Time|\n",
    "|---------|---------|--------|------|--|-------------|\n",
    "|KNN -> n_neighbors = 2 |  0.947  |  0.948  | 0.949  | 0.947  |   0.198s   |\n",
    "|KNN -> n_neighbors = 5 |  0.952  |  0.952  | 0.952  | 0.952  |   0.189s   |\n",
    "|KNN -> n_neighbors = 8 |  0.948  |  0.949  | 0.948  | 0.948  |  0.187s    |\n",
    "|RandomForest-> n_estimators = 50 |  0.957  | 0.958  | 0.958  |  0.958 | 0.932s |\n",
    "|RandomForest-> n_estimators = 100 | 0.960   | 0.961  | 0.961 | 0.961  | 1.813s |\n",
    "|RandomForest-> n_estimators = 150 | 0.962   | 0.963  | 0.963 | 0.963  | 2.734s |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because RandomForest is an ensemble methods that it need to train multiple base classifiers to combine, it needs much more time to train compared with KNN (2.734s is 15X of 0.187s). More number of trees in the forest, it needs more training time but can achieve better performance. However, in KNN, the training time becomes smaller when `n_neighbors` becomes larger. The best `n_neighbors` is  5 and the best accuracy that KNN achieves is about 0.952 which is lower than the performance of RandomForest's best accuracy 0.962. \n",
    "\n",
    "In a word, RandomForest classifiers reduces the variance and has better performnce than KNN but need more time to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
